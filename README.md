# MULCIA-PLNLangDetection

Second work proposed for the subject of Natural Language Processing that consists of making a system that detects the languages of the text given.

## Requirements

System must support at least 10 languages. Languages must have differences between them. It is advisable to use the corpus [Europarl](http://www.statmt.org/europarl/). As minimum system must support Spanish, Italian, French, Portuguese and English.

System must differentiate between train process and evaluation process. For each language, needed at least a corpus with a million of words for training, and about 100.000 words for evaluating.

Systen should not require training for each use.

For evaluating, needs to split evaluating corpus in 1-20 words groups randomly. 

Finally, system must calculate percentage of hits and erros. And, it is important that system builds a confusing matrix with 2 dimensions for all languages combinations.

## Technologies

* [python3](https://www.python.org/download/releases/3.0/)
* [pip3](https://pypi.python.org/pypi/pip)
* [scikit-learn](http://scikit-learn.org/)
* [nltk](http://www.nltk.org/)
* [numpy](http://www.numpy.org/) 
* [scipy](https://www.scipy.org/)
* [tqdm](https://pypi.python.org/pypi/tqdm)
* [wikipedia](https://pypi.python.org/pypi/wikipedia/)

## Languages supported

This project has target of supporting following 10 lenguages: english, spanish, french, italian, protuguese, german, greek, danish, netherlander and finnish. But, it supports other languages.

## Instalation

...

## How to execute

...